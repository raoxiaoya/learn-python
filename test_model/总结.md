#### 一、使用modelscope提供的notebook进行测试

https://developer.aliyun.com/article/995577

![image-20250701094709443](D:\dev\php\magook\trunk\server\md\img\image-20250701094709443.png)

在modelscope平台需要绑定你的个人阿里云账号，点击“查看Notebook”时会要求登录阿里云，这两者要一致，我用的是支付宝扫码登录。

Notebook其实就是一个Jupyter Notebook服务。工作目录在 /mnt/workspace/。

点击加号可以创建文件、终端、ipynb。

点击上传按钮可以将本地文件上传上来，比如 requirements.txt。

![image-20250701100953081](D:\dev\php\magook\trunk\server\md\img\image-20250701100953081.png)

要及时保存文件！！！超过1小时没有操作就会被收回。

下次你启动同一台机器，你的环境还在，`.ipynb` 以外的文件不会自动存储。



**本机配置**

windows10, CPU-intel i7, 16G内存



#### 二、人像卡通化

DCT-Net（Domain-Calibrated Translation）

https://modelscope.cn/models/iic/cv_unet_person-image-cartoon_compound-models/summary

环境

```bash
conda create -n tensorflow2.19.0 python==3.10.16
conda activate tensorflow2.19.0
```

依赖

```bash
absl-py==2.3.0
addict==2.4.0
aiohappyeyeballs==2.6.1
aiohttp==3.12.13
aiosignal==1.3.2
astunparse==1.6.3
async-timeout==5.0.1
attrs==25.3.0
certifi==2025.6.15
charset-normalizer==3.4.2
colorama==0.4.6
contourpy==1.3.2
cycler==0.12.1
datasets==3.2.0
dill==0.3.8
easydict==1.13
filelock==3.18.0
flatbuffers==25.2.10
fonttools==4.58.4
frozenlist==1.7.0
fsspec==2024.9.0
gast==0.6.0
google-pasta==0.2.0
grpcio==1.73.1
h5py==3.14.0
huggingface-hub==0.33.1
idna==3.10
Jinja2==3.1.6
joblib==1.5.1
keras==3.10.0
kiwisolver==1.4.8
libclang==18.1.1
Markdown==3.8.2
markdown-it-py==3.0.0
MarkupSafe==3.0.2
matplotlib==3.10.3
mdurl==0.1.2
ml_dtypes==0.5.1
modelscope==1.27.1
mpmath==1.3.0
multidict==6.6.2
multiprocess==0.70.16
namex==0.1.0
networkx==3.4.2
numpy==2.1.3
opencv-contrib-python==4.11.0.86
opencv-python==4.11.0.86
opt_einsum==3.4.0
optree==0.16.0
packaging==25.0
pandas==2.3.0
pillow==11.2.1
propcache==0.3.2
protobuf==5.29.5
pyarrow==20.0.0
Pygments==2.19.2
pyparsing==3.2.3
python-dateutil==2.9.0.post0
pytz==2025.2
PyYAML==6.0.2
requests==2.32.4
rich==14.0.0
scikit-learn==1.7.0
scipy==1.15.3
simplejson==3.3.0
six==1.17.0
sortedcontainers==2.4.0
sympy==1.14.0
tensorboard==2.19.0
tensorboard-data-server==0.7.2
tensorflow==2.19.0
tensorflow-io-gcs-filesystem==0.31.0
termcolor==3.1.0
threadpoolctl==3.6.0
torch==2.7.1
torchvision==0.22.1
tqdm==4.67.1
typing_extensions==4.14.0
tzdata==2025.2
urllib3==2.5.0
Werkzeug==3.1.3
wrapt==1.17.2
xxhash==3.5.0
yarl==1.20.1
```

```bash
pip install -r requirements.txt
```

代码

```python
import cv2
from modelscope.outputs import OutputKeys
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks

img_cartoon = pipeline(Tasks.image_portrait_stylization, 
                       model='iic/cv_unet_person-image-cartoon_compound-models')
# 图像本地路径
img_path = '20250630105841.png'
dst_path = '20250630105841_carton.png'

# 图像url链接
# img_path = 'https://modelscope.oss-cn-beijing.aliyuncs.com/test/images/image_cartoon.png'

result = img_cartoon(img_path)
cv2.imwrite(dst_path, result[OutputKeys.OUTPUT_IMG])
print('finished!')

img1 = cv2.imread(img_path, cv2.IMREAD_COLOR)
img2 = cv2.imread(dst_path, cv2.IMREAD_COLOR)
cv2.imshow(img_path, img1)
cv2.imshow(dst_path, img2)
cv2.waitKey(0)
```

这个模型比较小，在CPU上即可运行，而且它的输出是确定的，因为不论我运行多少次，我的 git 仓库都是不变的。

![image-20250701102207470](D:\dev\php\magook\trunk\server\md\img\image-20250701102207470.png)





#### 三、人像美肤

ABPN：https://modelscope.cn/models/iic/cv_unet_skin-retouching/summary

```python
import cv2
from modelscope.outputs import OutputKeys
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks

skin_retouching = pipeline(Tasks.skin_retouching,model='iic/cv_unet_skin-retouching')

img_path = 'skin_retouching_examples_1.jpg'
dst_path = 'skin_retouching_examples_1_beauty.jpg'

# https://modelscope.oss-cn-beijing.aliyuncs.com/demo/skin-retouching/skin_retouching_examples_1.jpg

result = skin_retouching(img_path)
cv2.imwrite(dst_path, result[OutputKeys.OUTPUT_IMG])
print('finished!')

img1 = cv2.imread(img_path, cv2.IMREAD_COLOR)
img2 = cv2.imread(dst_path, cv2.IMREAD_COLOR)
cv2.imshow(img_path, img1)
cv2.imshow(dst_path, img2)
cv2.waitKey(0)
```



![image-20250701104358418](D:\dev\php\magook\trunk\server\md\img\image-20250701104358418.png)



#### 四、语音识别（Speech To Text）

SenseVoiceSmall：https://modelscope.cn/models/iic/SenseVoiceSmall/summary

体验地址：https://www.modelscope.cn/studios/iic/SenseVoice

多语言音频理解模型，具有包括语音识别、语种识别、语音情感识别，声学事件检测能力。

```python
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks

inference_pipeline = pipeline(
    task=Tasks.auto_speech_recognition,
    model='iic/SenseVoiceSmall',
    model_revision="master",
    disable_update=True,
    # device="cuda:0",
)

rec_result = inference_pipeline(
    'https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.wav')
print(rec_result)
```

此模型在我的电脑上无法正常运行，需要安装visual studio，可能是需要编译什么程序，算了，我直接到 modelscope Notebook 上运行

![image-20250701150949086](D:\dev\php\magook\trunk\server\md\img\image-20250701150949086.png)

```json
[{'key': 'asr_example_zh', 'text': '<|zh|><|NEUTRAL|><|Speech|><|woitn|>欢迎大家来体验达摩院推出的语音识别模型'}]
```

key 为音频文件；NEUTRAL 为情感中性。



#### 五、语言合成与控制（Text To Speech）

CosyVoice2

modelscope：https://modelscope.cn/models/iic/CosyVoice2-0.5B/summary

github：https://github.com/FunAudioLLM/CosyVoice

wenui：https://www.modelscope.cn/studios/iic/CosyVoice2-0.5B

demo及精细化控制：https://funaudiollm.github.io/cosyvoice2/

![image-20250702095601022](D:\dev\php\magook\trunk\server\md\img\image-20250702095601022.png)

**使用说明**

- 输入合成文本：就是最后要说的话。
- 速度调节：新版的UI有一个速度调节，用来调节输出的语速快慢
- 推理模式：1、3s极速复刻：提供要复刻的声音以及声音对应的文本。2、自然语音控制：除了提供声音和文本外，还可以在输入文本中插入细粒度的控制（Fine-grained Control），还可以提供指令（instruct）文本，比如使用什么语言，方言，情感等来控制输出。参考 https://funaudiollm.github.io/cosyvoice2/

**测试一下**

使用的prompt音频是CosyVoice的 [zero_shot_prompt.wav](https://github.com/FunAudioLLM/CosyVoice/blob/main/asset/zero_shot_prompt.wav)，它会自动识别出prompt文本，如果有误你可以修正一下。

输出效果还是挺不错的，一个16秒的语音耗时将近20秒，很明显模型里面使用了自然语言处理，因此对算力有一定的要求。本地无法运行，GPU内存>=8G

**代码测试**

根据CosyVoice项目的说明来操作，也就是说，是在CosyVoice上面做的二开。

```bash
git clone --recursive https://github.com/FunAudioLLM/CosyVoice.git
# recursive 表示会把submodule也拉下来

cd CosyVoice

# 创建环境
conda create -n cosyvoice python=3.10.16
conda activate cosyvoice

# 安装依赖
pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com
```

打开 CosyVoice 项目，在根目录下创建 test.py 文件。

```python
from modelscope import snapshot_download
import torchaudio
from cosyvoice.utils.file_utils import load_wav
from cosyvoice.cli.cosyvoice import CosyVoice, CosyVoice2
import sys

sys.path.append('third_party/Matcha-TTS')

download_dir = 'D:/dev/php/magook/trunk\server/ai_models/pretrained_models'
prompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)


def download_models():
    snapshot_download('iic/CosyVoice2-0.5B',
                      local_dir=download_dir+'/CosyVoice2-0.5B')
    snapshot_download('iic/CosyVoice-300M',
                      local_dir=download_dir+'/CosyVoice-300M')
    snapshot_download('iic/CosyVoice-300M-SFT',
                      local_dir=download_dir+'/CosyVoice-300M-SFT')
    snapshot_download('iic/CosyVoice-300M-Instruct',
                      local_dir=download_dir+'/CosyVoice-300M-Instruct')
    snapshot_download('iic/CosyVoice-ttsfrd',
                      local_dir=download_dir+'/CosyVoice-ttsfrd')


def run_models():
    cosyvoice = CosyVoice2(download_dir+'/CosyVoice2-0.5B',
                           load_jit=False, load_trt=False, load_vllm=False, fp16=False)

    # NOTE if you want to reproduce the results on https://funaudiollm.github.io/cosyvoice2, please add text_frontend=False during inference
    # zero_shot usage
    for i, j in enumerate(cosyvoice.inference_zero_shot('收到好友从远方寄来的生日礼物，那份意外的惊喜与深深的祝福让我心中充满了甜蜜的快乐，笑容如花儿般绽放。', '希望你以后能够做的比我还好呦。', prompt_speech_16k, stream=False)):
        torchaudio.save('zero_shot_{}.wav'.format(
            i), j['tts_speech'], cosyvoice.sample_rate)

    # save zero_shot spk for future usage
    assert cosyvoice.add_zero_shot_spk(
        '希望你以后能够做的比我还好呦。', prompt_speech_16k, 'my_zero_shot_spk') is True
    for i, j in enumerate(cosyvoice.inference_zero_shot('收到好友从远方寄来的生日礼物，那份意外的惊喜与深深的祝福让我心中充满了甜蜜的快乐，笑容如花儿般绽放。', '', '', zero_shot_spk_id='my_zero_shot_spk', stream=False)):
        torchaudio.save('zero_shot_{}.wav'.format(
            i), j['tts_speech'], cosyvoice.sample_rate)
    cosyvoice.save_spkinfo()

    # fine grained control, for supported control, check cosyvoice/tokenizer/tokenizer.py#L248
    for i, j in enumerate(cosyvoice.inference_cross_lingual('在他讲述那个荒诞故事的过程中，他突然[laughter]停下来，因为他自己也被逗笑了[laughter]。', prompt_speech_16k, stream=False)):
        torchaudio.save('fine_grained_control_{}.wav'.format(i),
                        j['tts_speech'], cosyvoice.sample_rate)

    # instruct usage
    for i, j in enumerate(cosyvoice.inference_instruct2('收到好友从远方寄来的生日礼物，那份意外的惊喜与深深的祝福让我心中充满了甜蜜的快乐，笑容如花儿般绽放。', '用四川话说这句话', prompt_speech_16k, stream=False)):
        torchaudio.save('instruct_{}.wav'.format(
            i), j['tts_speech'], cosyvoice.sample_rate)

    # bistream usage, you can use generator as input, this is useful when using text llm model as input
    # NOTE you should still have some basic sentence split logic because llm can not handle arbitrary sentence length


def text_generator():
    yield '收到好友从远方寄来的生日礼物，'
    yield '那份意外的惊喜与深深的祝福'
    yield '让我心中充满了甜蜜的快乐，'
    yield '今天真是太开心啦，吃到了最想吃的正新鸡排，抢到了梦寐以求的Labubu，和闺蜜们在东湖绿道骑车 吹着凉爽的风，欣赏着醉人的景，一切都是那么美好。'


def run_models2():
    cosyvoice = CosyVoice2(download_dir+'/CosyVoice2-0.5B',
                           load_jit=False, load_trt=False, load_vllm=False, fp16=False)
    for i, j in enumerate(cosyvoice.inference_zero_shot(text_generator(), '希望你以后能够做的比我还好呦。', prompt_speech_16k, stream=False)):
        torchaudio.save('zero_shot_{}.wav'.format(
            i), j['tts_speech'], cosyvoice.sample_rate)


if __name__ == '__main__':
    download_models()
    # run_models()
    # run_models2()

```

我们先要下载模型，总共有21G。执行`python test.py`

![image-20250702143621551](D:\dev\php\magook\trunk\server\md\img\image-20250702143621551.png)

还要安装 ffmpeg，这是用来处理音频视频的工具，否则会提示`Couldn't find ffprobe or avprobe`。此处下载ffmpeg-7.1.1版本，https://www.gyan.dev/ffmpeg/builds/ffmpeg-release-essentials.zip，解压到一个目录，然后将 bin 目录添加到环境变量，就是三个可执行程序 `ffmpeg.exe, ffplay.exe, ffprobe.exe`。

可以直接运行webui，要先切换到cosyvoice环境：`python webui.py --port 50000 --model_dir D:/dev/php/magook/trunk/server/ai_models/pretrained_models/CosyVoice2-0.5B`，启动后的UI就是 https://www.modelscope.cn/studios/iic/CosyVoice2-0.5B 。

`python webui.py --port 50000 --model_dir D:/dev/php/magook/trunk/server/ai_models/pretrained_models/CosyVoice2-0.5B`

或者运行`run_models()` 或者 `run_models2()`来生成语音。

![image-20250702152943747](D:\dev\php\magook\trunk\server\md\img\image-20250702152943747.png)

webui 虽然能启动，但是实在无法生成音频。

换到 modelscope notebook 上试一下。

![image-20250702162541468](D:\dev\php\magook\trunk\server\md\img\image-20250702162541468.png)

git 居然不能拉下来 CosyVoice 项目，只好将本地的打包在上传上去，环境里也没有anaconda，只好自己安装。

```bash
cd /mnt/workspace
wget -c 'https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Linux-x86_64.sh'

chmod +x Anaconda3-2023.09-0-Linux-x86_64.sh
sh Anaconda3-2021.11-Linux-x86_64.sh
source ~/.bashrc
conda env list

cd cosyvoice
mkdir pretrained_models
conda create -n cosyvoice python=3.10.16
conda activate cosyvoice
pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com --resume-retries=3
```

我们只需要下载一个模型`CosyVoice2-0.5B`，把其他的屏蔽掉。

下载完之后，我们来运行`run_models2()`

运行完之后成功生成了`zero_shot_0.wav`文件，将其下载下来听一下，与线上的效果一样。

![image-20250702175547710](D:\dev\php\magook\trunk\server\md\img\image-20250702175547710.png)

<audio src="F:\zero_shot_0.wav"></audio>

我们把这个音频使用SenseVoiceSmall识别一下，输出如下

```bash
[{'key': 'zero_shot_0', 'text': '<|zh|><|HAPPY|><|Speech|><|woitn|>收到好友从远方寄来的生日礼物那份意外的惊喜与深深的祝福让我心中充满了甜蜜的快乐今天真是太开心了吃到了最想吃的正新鸡排抢到了梦寐以求的雷布布和闺蜜们在东湖绿道骑车吹着凉爽的风欣赏着醉人的景一切都是那么美好'}]
```



#### 六、Flux.1 Kontext

在 Flux 提供的平台上测试 https://playground.bfl.ai/

![image-20250703113715543](D:\dev\php\magook\trunk\server\md\img\image-20250703113715543.png)

```bash
Change this female character's outfit to a white long dress, while keeping the character IP and pose unchanged
```

![image-20250703113745490](D:\dev\php\magook\trunk\server\md\img\image-20250703113745490.png)

```bash
Change the image to Ghibli style
```

![image-20250703113500331](D:\dev\php\magook\trunk\server\md\img\image-20250703113500331.png)

```bash
Raise the girl's right hand and make a victory gesture
```

![image-20250703113857169](D:\dev\php\magook\trunk\server\md\img\image-20250703113857169.png)

```bash
Make the female model turn around to reveal her side face
```

![image-20250703114115721](D:\dev\php\magook\trunk\server\md\img\image-20250703114115721.png)

```bash
Make the female model turn around so that she is facing away from the audience.
```

![image-20250703114403282](D:\dev\php\magook\trunk\server\md\img\image-20250703114403282.png)

```bash
Change the image's background to that of a park with a small stream.
```

![image-20250703114700160](D:\dev\php\magook\trunk\server\md\img\image-20250703114700160.png)



```bash
老照片修复：修复这张老照片，修复破损、发黄、褶皱等各种问题，并处理成彩色

换衣服：修复这张老照片，修复破损、发黄、褶皱等各种问题，并处理成彩色，女人的上衣改为红色

Restore this old photograph by addressing all defects including tears, yellowing, and creases. Process it to be in color and modify the woman's blouse to be red.

让两个女人在美丽的海滩上拥抱
```









