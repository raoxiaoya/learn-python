深度学习 Deep Learning 笔记（二）-应用数学与机器学习基础

![image-20240624165819287](D:\dev\php\magook\trunk\server\md\img\image-20240624165819287.png)



latexocr 命令



### 二、线性代数 Linear Algebra

28页开始

线性代数主要是面向连续数学，而非离散数学。



#### 2.1、标量，向量，矩阵，张量

标量：就是一个数字。

向量：一维数组，是一列。使用小写字母加粗的斜体表示，比如 ***b***

矩阵：二维数组。使用大写字母加粗斜体表示，比如 ***A***

张量：多维数组，它可以是任意维度，特殊的：0阶张量是标量，1阶张量是向量，2阶张量是矩阵。

矩阵转置：沿着左上角到右下角的对角线镜像。特殊的，只有一行元素的矩阵的T操作就是向量，有时，我们通过将向量元素作为行矩阵写在文本行中，然后使用转置操作将其变为标准的列向量。标量可以看作是只有一个元素的矩阵。因此，标量的转置等于它本身。
$$
(A^{\top})_{i,j}=A_{j,i}
$$
![image-20240624163529553](D:\dev\php\magook\trunk\server\md\img\image-20240624163529553.png)

#### 2.2、矩阵和向量的运算

矩阵的加减：矩阵的形状要一样，对应位置上的加减。

标量和矩阵运算：逐个元素运算。

矩阵和向量相加：要求向量的维度和矩阵列数相等，向量和矩阵的每一行相加，得到另一个矩阵。
$$
\left[{\begin{array}{r r r}{1}&{1}&{1}\\ {2}&{2}&{2}\\ {3}&{3}&{3}\end{array}}\right]
+
\left[{\begin{array}{r}{1}\\ {2}\\ {3}\end{array}}\right]
=
\left[{\begin{array}{r r r}{2}&{3}&{4}\\ {3}&{4}&{5}\\ {4}&{5}&{6}\end{array}}\right]
$$
矩阵乘以向量：***Ax*** = ***b*** ，矩阵的每一行与向量相乘，最后得到一个向量。
$$
\left[{\begin{array}{r r r}{1}&{1}&{1}\\ {2}&{2}&{2}\\ {3}&{3}&{3}\end{array}}\right]
\left[{\begin{array}{r}{1}\\ {2}\\ {3}\end{array}}\right]
=
\left[{\begin{array}{r}{6}\\ {12}\\ {18}\end{array}}\right]
$$


矩阵相乘：或者叉乘，记为 ***A × B***，或 ***AB***，要求***A***的列数等于***B***的行数，如果矩阵 ***A*** 的形状是 *m* *×* *n*，矩阵 ***B*** 的形状是 *n* *×* *p*，那么矩阵 ***C*** 的形状是 *m* *×* *p*。

矩阵相乘的特性：

- 矩阵相乘服从分配律，即 ***A**(**B** + **C**) = **AB** + **AC***。
- 也服从结合律，***A**(**BC**) = (**AB**)**C***。
- 但是不满足交换律，***AB** != **BA***。
- ***AB*** 的转置等于 ***B*** 的转置乘以 ***A*** 的转置。



矩阵点乘：记为 ***A · B***，各个对应元素相乘，要求矩阵的形状相等。用的少。



#### 2.3、单位矩阵和逆矩阵

单位矩阵：主对角线上的元素都是1，其他元素都是0，单位矩阵记为 ***I***。任何向量乘以单位矩阵都是向量本身。
$$
\left[{\begin{array}{r r r}{1}&{0}&{0}\\ {0}&{1}&{0}\\ {0}&{0}&{1}\end{array}}\right]
$$
矩阵的逆：满足公式 `A的逆 乘以 A 等于一个单位矩阵`。
$$
A^{-1}A=I_{n}
$$

$$
由 Ax=b ，可以推导出， x = A^{-1}b
$$

对于方阵（m=n）来说，它的左逆和右逆是相等的。
$$
A^{-1}A=AA^{-1}
$$


#### 2.4、线性相关和生成子空间

33页 看不懂

针对方程 ***Ax=b***，假如***x***和***y***都是它的解，那么 ***z*** = α***x*** + (1 *−* *α*)***y*** 也是它的解，其中 α 取任意实数。扩展一下，针对任意方程，该结论也成立。

![image-20240628162305849](D:\dev\php\magook\trunk\server\md\img\image-20240628162305849.png)

![image-20240628162502992](D:\dev\php\magook\trunk\server\md\img\image-20240628162502992.png)

![image-20240628162533504](D:\dev\php\magook\trunk\server\md\img\image-20240628162533504.png)

![image-20240628162549684](D:\dev\php\magook\trunk\server\md\img\image-20240628162549684.png)

**线性相关**

在线性代数里，矢量空间的一组元素中，若没有矢量可用有限个其他矢量的线性组合所表示，则称为线性无关或线性独立(linearly independent)，反之称为线性相关(linearly dependent)。例如在三维欧几里得空间R3的三个矢量(1, 0, 0)，(0, 1, 0)和(0, 0, 1)线性无关。但(2, −1, 1)，(1, 0, 1)和(3, −1, 2)线性相关，因为第三个是前两个的和。



#### 2.5、范数

向量的范数是一种用来刻画向量大小的一种度量。实数的绝对值，复数的模，三维空间向量的长度，都是抽象范数概念的原型。上述三个对象统一记为 x ，衡量它们大小的量记为 ‖x‖ （我们用单竖线表示绝对值，双竖线表示范数）

**向量的范数和模的区别：**向量的模是一个绝对值，指向量在二维或三维空间中的长度；范数是一个函数，它能表示向量在 N 维空间的长度。

![image-20240628163626981](D:\dev\php\magook\trunk\server\md\img\image-20240628163626981.png)

![image-20240628164726626](D:\dev\php\magook\trunk\server\md\img\image-20240628164726626.png)

![image-20240628164924133](D:\dev\php\magook\trunk\server\md\img\image-20240628164924133.png)



**向量的点乘**

```
x·y = x1*x2 + y1*y2 = ‖x‖‖y‖cosθ
```



#### 2.6、特殊类型的矩阵和向量

有些特殊类型的矩阵和向量是特别有用的。

![image-20240628172316579](D:\dev\php\magook\trunk\server\md\img\image-20240628172316579.png)

![image-20240628172857264](D:\dev\php\magook\trunk\server\md\img\image-20240628172857264.png)

![image-20240628173612327](D:\dev\php\magook\trunk\server\md\img\image-20240628173612327.png)

#### 2.7、特征分解

