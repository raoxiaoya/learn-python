深度学习 Deep Learning 笔记（6）-深度前馈网络



深度前馈网络（deep feedforward network），也叫作 前馈神经网络（feedforward neural network）或者 多层感知机（multilayer perceptron, MLP），是典型的深度学习模型。前馈网络的目标是近似某个函数 *f*。例如，对于分类器，*y* = *f*  (**x**) 将输入**x** 映射到一个类别 *y*。前馈网络定义了一个映射 **y** = *f*(**x**; **θ**)，并且学习参数 **θ** 的值，使它能够得到最佳的函数近似。

这种模型被称为 前向（feedforward）的，是因为信息流过 **x** 的函数，流经用于定义 *f* 的中间计算过程，最终到达输出 **y**。在模型的输出和模型本身之间没有 反馈（feedback）连接。当前馈神经网络被扩展成包含反馈连接时，它们被称为 循环神经网络（recurrent neural network），在第十章介绍。

前馈网络对于机器学习的从业者是极其重要的。它们是许多重要商业应用的基础。例如，用于对照片中的对象进行识别的卷积神经网络就是一种专门的前馈网络。前馈网络是通往循环网络之路的概念基石，后者在自然语言的许多应用中发挥着巨大作用。

![image-20240828160137575](D:\dev\php\magook\trunk\server\md\img\image-20240828160137575.png)



 

**ReLU**：整流线性单元（rectified linear unit），数 g(z) = max*{*0, z}



**输出单元**

代价函数的选择与输出单元的选择紧密相关。大多数时候，我们简单地使用数据分布和模型分布间的交叉熵。选择如何表示输出决定了交叉熵函数的形式。常用的激活函数有sigmoid，softmax。



**隐藏单元**

优先选择的激活函数有：ReLU > tanh > sigmoid

通常不可能预先预测出哪种隐藏单元工作得最好。设计过程充满了试验和错误，先直觉认为某种隐藏单元可能表现良好，然后用它组成神经网络进行训练，最后用验证集来评估它的性能。大多数隐藏单元的区别仅仅在于激活函数 *g*(**z**) 的形式。



#### 6.4、架构设计

神经网络设计的另一个关键点是确定它的架构。 架构（architecture）一词是指网络的整体结构：它应该具有多少单元，以及这些单元应该如何连接。

大多数神经网络被组织成称为层的单元组。大多数神经网络架构将这些层布置成链式结构，其中每一层都是前一层的函数。在这种结构中，第一层由下式给出：
$$
h^{(1)}=g^{(1)}(W^{(1)T}x+b^{(1)})
$$
第二层
$$
h^{(2)}=g^{(2)}(W^{(2)T}h^{(1)}+b^{(2)})
$$
以此类推。

在这些链式架构中，主要的架构考虑是选择网络的深度和每一层的宽度。我们将会看到，即使只有一个隐藏层的网络也足够适应训练集。更深层的网络通常能够对每一层使用更少的单元数和更少的参数，并且经常容易泛化到测试集，但是通常也更难以优化。对于一个具体的任务，理想的网络架构必须通过实验，观测在验证集上的误差来找到。



万能近似定理意味着无论我们试图学习什么函数，我们知道一个大的 MLP 一定能够表示这个函数。然而，我们不能保证训练算法能够学得这个函数。即使 MLP能够表示该函数，学习也可能因两个不同的原因而失败。首先，用于训练的优化算法可能找不到用于期望函数的参数值。其次，训练算法可能由于过拟合而选择了错误的函数。

前馈网络提供了表示函数的万能系统，在这种意义上，给定一个函数，存在一个前馈网络能够近似该函数。不存在万能的过程既能够验证训练集上的特殊样本，又能够选择一个函数来扩展到训练集上没有的点。

关于如何选择网络的深度（层数）和宽度（每层的单元数）。在很多情况下，使用更深的模型能够减少表示期望函数所需的单元的数量，并且可以减少泛化误差。存在一些函数族能够在网络的深度大于某个值 *d* 时被高效地近似，而当深度被限制到小于或等于 *d* 时需要一个远远大于之前的模型。在很多情况下，浅层模型所需的隐藏单元的数量是 *n* 的指数级。

![image-20240829105055065](D:\dev\php\magook\trunk\server\md\img\image-20240829105055065.png)

![image-20240829105628209](D:\dev\php\magook\trunk\server\md\img\image-20240829105628209.png)

架构设计考虑的另外一个关键点是如何将层与层之间连接起来。默认的神经网络层采用矩阵 **W** 描述的线性变换，每个输入单元连接到每个输出单元。中的许多专用网络具有较少的连接，使得输入层中的每个单元仅连接到输出层单元的一个小子集。这些用于减少连接数量的策略减少了参数的数量以及用于评估网络的计算量，但通常高度依赖于具体使用场景。



#### 6.5、反向传播



